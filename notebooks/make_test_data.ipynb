{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Yelp: Make Test Data"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.1.1\n      /_/\n                        \nUsing Scala version 2.12.13, OpenJDK 64-Bit Server VM, 1.8.0_292\nBranch HEAD\nCompiled by user  on 2021-06-23T22:10:53Z\nRevision e9c1449899ac58a10ea28ca6f1e8ed6c7c254d54\nUrl https://bigdataoss-internal.googlesource.com/third_party/apache/spark\nType --help for more information.\n"}], "source": "!spark-shell --version"}, {"cell_type": "markdown", "metadata": {}, "source": "<details>\n<summary><b>Table of Contents</b> (click to open)</summary>\n<!-- MarkdownTOC -->\n\n1. [Load Full Dataset](#data)\n1. [Make Input Test Data](#Source-Test-Data)\n1. [Make Expected Test Data](#Make-Expected-Test-Data)\n    1. [Testcase: Top Businesses](#Testcase:-Top-Businesses)\n    1. [Testcase: Top Restaurants](#Testcase:-Top-Restaurants)\n 1. [Copy Test Data to Project Folder](#Copy-Test-Data-to-Project-Folder)\n    1. [Input Test Data](#Input-Test-Data)\n    1. [Expected Test Data](#Expected-Test-Data)\n    \n<!-- /MarkdownTOC -->\n</details>"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": "# Import Required Libraries\nimport pyspark.sql.functions as F"}, {"cell_type": "markdown", "metadata": {}, "source": "### Load Data  <a class=\"anchor\" id=\"data\"></a>"}, {"cell_type": "markdown", "metadata": {}, "source": "Load the data from google cloud storage to dataproc"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "file_review = \"gs://proj-spark/yelp-dataset/yelp_academic_dataset_review.json\"\nfile_business = \"gs://proj-spark/yelp-dataset/yelp_academic_dataset_business.json\"\nfile_users = \"gs://proj-spark/yelp-dataset/yelp_academic_dataset_user.json\"\nfile_checkin = \"gs://proj-spark/yelp-dataset/yelp_academic_dataset_checkin.json\"\nfile_tip = \"gs://proj-spark/yelp-dataset/yelp_academic_dataset_tip.json\""}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "df_review = spark.read.format('json').load(file_review)\ndf_review.createOrReplaceTempView('reviewTable')\n\ndf_business = spark.read.format('json').load(file_business)\ndf_business.createOrReplaceTempView('businessTable')\n\ndf_users = spark.read.format('json').load(file_users)\ndf_users.createOrReplaceTempView('usersTable')\n\ndf_checkin = spark.read.format('json').load(file_checkin)\ndf_checkin.createOrReplaceTempView('checkinTable')\n\ndf_tip = spark.read.format('json').load(file_tip)\ndf_tip.createOrReplaceTempView('checkinTable')"}, {"cell_type": "markdown", "metadata": {}, "source": "### Source Test Data"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "expected_data_path = '/home/bilal/study_private/tests/test_data/expected_data/'\nsource_data_path = '/home/bilal/study_private/tests/test_data/source_data/'"}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [], "source": "def make_checkin_data(df_checkin):\n    df_checkin_test = df_checkin.sample(withReplacement=False, fraction=0.05, seed=50)\\\n                                .limit(200)\\\n                                .coalesce(1)\n    df_checkin_test.write.format('json').save('source_data/yelp_academic_dataset_checkin.json')"}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": "def make_business_data(df_business):\n    df_checkin_test = spark.read.format('json').load('source_data/yelp_academic_dataset_checkin.json')\n    joinExpr = df_business.business_id == df_checkin_test.business_id\n    df_business_test = df_business.join(F.broadcast(df_checkin_test), joinExpr, 'inner')\\\n                                  .drop(df_checkin_test.business_id)\\\n                                  .coalesce(1)\n    df_business_test.write.format('json').save('source_data/yelp_academic_dataset_business.json')"}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [], "source": "def verify(df1, df2, key):\n    df1_key = df1.groupby(key).agg(F.count(key))\n    df2_key = df2.groupby(key).agg(F.count(key))\n    if df1_key.subtract(df2_key).rdd.isEmpty():\n        return df2_key.subtract(df1_key).rdd.isEmpty()\n    return False"}, {"cell_type": "code", "execution_count": 61, "metadata": {}, "outputs": [], "source": "make_checkin_data(df_checkin)\nmake_business_data(df_business)"}, {"cell_type": "code", "execution_count": 62, "metadata": {}, "outputs": [], "source": "df_checkin_test = spark.read.format('json').load('source_data/yelp_academic_dataset_checkin.json')\ndf_business_test = spark.read.format('json').load('source_data/yelp_academic_dataset_business.json')"}, {"cell_type": "code", "execution_count": 127, "metadata": {}, "outputs": [{"data": {"text/plain": "True"}, "execution_count": 127, "metadata": {}, "output_type": "execute_result"}], "source": "# verify that both dataframes have same business_ids\nverify(df_checkin_test, df_business_test, 'business_id')"}, {"cell_type": "markdown", "metadata": {}, "source": "###  Make Expected Test Data"}, {"cell_type": "code", "execution_count": 34, "metadata": {}, "outputs": [], "source": "# load data from gcs to dataproc\ndf_checkin_test = spark.read.format('json')\\\n            .load('gs://proj-spark/yelp-test-dataset/yelp_academic_dataset_checkin.json')\ndf_business_test = spark.read.format('json')\\\n            .load('gs://proj-spark/yelp-test-dataset/yelp_academic_dataset_business.json')"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Testcase: Top Businesses"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": "# pandas dataframes\npdf_checkin_test = df_checkin_test.toPandas()\npdf_business_test = df_business_test.toPandas()\n\npdf_checkin_test['checkin_count'] = pdf_checkin_test.date.str.split(',').map(len)\npdf_checkin_bs = pdf_checkin_test.merge(pdf_business_test, on='business_id')\\\n                                 .sort_values(by=['checkin_count','business_id'], ascending=False)\n\npdf_expected_data_tc2 = pdf_checkin_bs[['business_id', 'name', 'city', 'state', 'stars', 'checkin_count', 'review_count']]"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "pdf_expected_data_tc2.to_csv('top_businesses.csv', index=False)"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Testcase: Top Restaurants"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": "pdf_checkin_rest = pdf_checkin_bs[pdf_checkin_bs.categories.str.contains('res', case=False)]\npdf_checkin_rest = pdf_checkin_rest[pdf_checkin_rest.state=='MA']\npdf_checkin_rest = pdf_checkin_rest.sort_values(by=['checkin_count','business_id'], ascending=False)\n\npdf_expected_data_tc3 = pdf_checkin_rest[['business_id', 'name', 'city', 'state', 'stars', 'checkin_count', 'review_count']]"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": "pdf_expected_data_tc3.to_csv('top_restaurants.csv', index=False)"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Testcase: Business Categories"}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [], "source": "# transform categories to category\npdf_business_test = df_business_test.toPandas()\npdf_business_test['category'] = pdf_business_test.categories.str.split(', ')\npdf_business_test = pdf_business_test.explode('category')\n\n# aggregate and sort\npdf_cat_grp = pdf_business_test.groupby('category')[['business_id']]\\\n                               .agg('count')\\\n                               .rename(columns={'business_id':'business_count'})\\\n                               .reset_index()\npdf_expected_data_tc4 = pdf_cat_grp.sort_values(['business_count','category'], ascending=False)"}, {"cell_type": "code", "execution_count": 53, "metadata": {}, "outputs": [], "source": "pdf_expected_data_tc4.to_csv('business_categories.csv', index=False)"}, {"cell_type": "code", "execution_count": 37, "metadata": {}, "outputs": [], "source": "# Split the categories \ndf_business_test = df_business_test.withColumn('categories_splitted', F.split(F.col('categories'),', '))\\\n    .withColumn('category', F.explode('categories_splitted'))\n\ncat_grp = df_business_test.groupBy('category')\\\n    .agg(F.count('business_id').alias('business_count'))\\\n    .orderBy(['business_count','category'], ascending=False)"}, {"cell_type": "code", "execution_count": 43, "metadata": {}, "outputs": [{"data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>business_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Restaurants</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Food</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Shopping</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Beauty &amp; Spas</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Nightlife</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>Airport Lounges</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>Air Duct Cleaning</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>Adult Education</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>Acupuncture</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>279</th>\n      <td>Acai Bowls</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>280 rows \u00d7 2 columns</p>\n</div>", "text/plain": "              category  business_count\n0          Restaurants              71\n1                 Food              46\n2             Shopping              29\n3        Beauty & Spas              26\n4            Nightlife              18\n..                 ...             ...\n275    Airport Lounges               1\n276  Air Duct Cleaning               1\n277    Adult Education               1\n278        Acupuncture               1\n279         Acai Bowls               1\n\n[280 rows x 2 columns]"}, "execution_count": 43, "metadata": {}, "output_type": "execute_result"}], "source": "pdf_expected_data_tc4.reset_index(drop=True)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Copy Test Data to Project Folder"}, {"cell_type": "markdown", "metadata": {}, "source": "### Input Test Data"}, {"cell_type": "markdown", "metadata": {}, "source": "Copy Source test data to project directory and google cloud storage"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# list files in source data\n!hdfs dfs -ls  /user/root/source_data\n\n# copy source_data from HDFS to Master Node\n!hdfs dfs -copyToLocal /user/root/source_data source_data\n\n# Move source_data to project folder\n!mv source_data/yelp_academic_dataset_checkin.json/part-*.json \\\n    $source_data_path/yelp_academic_dataset_checkin.json\n!mv source_data/yelp_academic_dataset_business.json/part-*.json \\\n    $source_data_path/yelp_academic_dataset_business.json\n\n# Copy source_data to google cloud storage\n!gsutil cp $source_data_path/yelp_academic_dataset_checkin.json \\\n           gs://proj-spark/yelp-test-dataset\n!gsutil cp $source_data_path/yelp_academic_dataset_business.json \\\n           gs://proj-spark/yelp-test-dataset\n    \n# Delete Data from HDFS \n!hdfs dfs -rm -r  /user/root/source_data\n\n# Delete Data from Master Node\n!rm -r source_data"}, {"cell_type": "markdown", "metadata": {}, "source": "### Expected Test Data"}, {"cell_type": "markdown", "metadata": {}, "source": "Copy expected data to project folder"}, {"cell_type": "code", "execution_count": 54, "metadata": {}, "outputs": [], "source": "!mv top_businesses.csv $expected_data_path/top_businesses.csv\n!mv top_restaurants.csv $expected_data_path/top_restaurants.csv\n!mv business_categories.csv $expected_data_path/business_categories.csv"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}, "toc-autonumbering": false, "toc-showmarkdowntxt": false}, "nbformat": 4, "nbformat_minor": 4}